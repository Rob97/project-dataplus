---
title: "Regression_models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, include=FALSE}
if(!require(mlbench)){install.packages("mlbench"); require(mlbench)} # common datasets to use
if(!require(tidyverse)){install.packages("tidyverse"); library(tidyverse)} 
if(!require(modelr)){install.packages("modelr"); library(modelr)} 

# some dependencies for caret that aren't automatically installed
if(!require(ModelMetrics)){install.packages("ModelMetrics"); require(ModelMetrics)}
if(!require(recipes)){install.packages("recipes"); require(recipes)}
if(!require(DEoptimR)){install.packages("DEoptimR"); require(DEoptimR)}

if(!require(caret)){install.packages("caret"); require(caret)} # ML package WITHOUT its dependencies. Should not take as long
if(!require(dplyr)){install.packages("dplyr"); require(dplyr)}
if(!require(jsonlite)){install.packages("jsonlite"); require(jsonlite)}
set.seed(370)

# if(!require(caret)){install.packages("caret", dependencies = c("Depends", "Suggests")); require(caret)} # ML package and its dependencies. Do NOT need to run for class. Would be good to install for use of caret in general. This will take awhile!
```

```{r, echo=FALSE, include=FALSE}
# Getting data
json_file <- "SeattleYelpRestaurants.json"
yelp.data <- fromJSON(json_file) %>% filter(!is.na(price)) %>% filter(!is.na(reviewCount)) %>% filter(!is.na(censusMedianHHIncome)) %>% filter(!is.na(censusIncomePerCapita)) %>% filter(!is.na(censusGiniIndexOfInequality)) %>% filter(!is.na(rating)) 

low <- quantile(yelp.data$censusMedianHHIncome, 0.33)
high <- quantile(yelp.data$censusMedianHHIncome, 0.66)

filtered.yelp <- subset(yelp.data, select=c("reviewCount", "censusMedianHHIncome", "censusIncomePerCapita", "censusGiniIndexOfInequality"))

price.num <- c(nchar(yelp.data[,"price"]))
filtered.yelp$price = price.num

filtered.yelp$rating = yelp.data[,"rating"]

below.avg <- filtered.yelp %>% filter(censusMedianHHIncome < low)
above.avg <- filtered.yelp %>% filter(censusMedianHHIncome > high)
```

## Correlation
```{r, echo=FALSE}
corr_matrix <- cor(filtered.yelp)# correlations between all predictor vars

cutoff <- 0.2 # should be higher in practice

highly_corr <- findCorrelation(corr_matrix, cutoff=cutoff)
print(colnames(filtered.yelp)[highly_corr]) # age is highly correalted with pregnant
```

## Ranked by Importance
```{r, echo=FALSE}
filtered.yelp.w.ratings <- filtered.yelp
no.na.rating <- yelp.data[,"rating"]
filtered.yelp.w.ratings$rating <- no.na.rating[!is.na(no.na.rating)]
control <- trainControl(method="repeatedcv", number = 10, repeats = 3)

model <- train(rating ~., data=filtered.yelp.w.ratings, method = "knn", preProcess = "scale", trControl = control)

importance <- varImp(model)

ggplot(importance)
```

## RFE
```{r, echo=FALSE}
control <- rfeControl(functions = rfFuncs, method="cv", number=10)
results <- rfe(filtered.yelp.w.ratings[,1:5], filtered.yelp.w.ratings[,6], sizes = c(1:5), rfeControl = control)

results
ggplot(results)
```

```{r, echo=FALSE, include=FALSE}
# splitting boston data into train+validate and test sets

split_proportion = 0.8

# select outcome variable
outcome <- filtered.yelp %>% dplyr::select(rating) # rating column only

# randomly select indices for train/validate set
train_ind <- createDataPartition(outcome$rating, p = split_proportion, list = FALSE)
filtered_yelp_train <- filtered.yelp[train_ind,] # get training data
filtered_yelp_test <- filtered.yelp[-train_ind,] # get test data

yelp_test_x <- filtered.yelp %>% dplyr::select(-rating) # select predictor data for test set
yelp_test_y <- filtered.yelp %>% dplyr::select(rating) # select outcome data for test set
```

```{r, echo=FALSE, include=FALSE}
ctrl <- trainControl(method = "repeatedcv", number=10, repeats=3) # 10 fold cross-validation, repeated 3 times. better way to do it but takes longer.
```

## Linear Regression
```{r, echo=FALSE}
model_lm <- train(rating ~ ., # outcome is "medv", all other columns are predictors
                  data = filtered_yelp_train, # training data
                  method = "lm", # model type (linear model)
                  trControl=ctrl) # evaluation method

# getting performance on test set (as root mean squared error (L2 norm), R^2, mean absolute error (L1 norm))
predict_yelp_lm <- predict(model_lm, yelp_test_x)
postResample(predict_yelp_lm, yelp_test_y$rating)

# creating grid of data to plot results for test set
grid <- filtered_yelp_test %>%
  gather_predictions(model_lm)

# getting important variales
varImp(model_lm)

# 5 features 
#censusIncomePerCapita
p1 <- ggplot(filtered_yelp_test, aes(as.factor(rating), censusIncomePerCapita)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p1

#censusGiniIndexOfInequality
p2 <- ggplot(filtered_yelp_test, aes(as.factor(rating), censusGiniIndexOfInequality)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p2

#reviewCount
p3 <- ggplot(filtered_yelp_test, aes(as.factor(rating), reviewCount)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p3

#censusMedianHHIncome
p4 <- ggplot(filtered_yelp_test, aes(as.factor(rating), censusMedianHHIncome)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red") +
  scale_y_continuous(name="censusMedianHHIncome", labels = scales::comma)

p4

#price 
p5 <- ggplot(filtered_yelp_test, aes(as.factor(rating), price)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p5

```

```{r}
# high SES SVM modeling
model_svm_high <- train(rating ~ .,
                  data = above.avg,
                  method = "svmRadial",
                  trControl=ctrl,   # Radial kernel
                  tuneLength = 10)

predict_yelp_svm_high <- predict(model_svm_high, below.avg)
postResample(predict_yelp_svm_high, below.avg$rating)

#actual minus predicted
delta <- below.avg$rating - predict_yelp_svm_high
count.line <- length(which(delta < 0)) / length(delta)
```


```{r}
# low svm ses
model_svm_low <- train(rating ~ .,
                  data = below.avg,
                  method = "svmRadial",
                  trControl=ctrl,   # Radial kernel
                  tuneLength = 10)

predict_yelp_svm_low <- predict(model_svm_low, above.avg)
postResample(predict_yelp_svm_low, above.avg$rating)

#actual minus predicted
delta_low <- above.avg$rating - predict_yelp_svm_low
count.line.low <- length(which(delta_low < 0)) / length(delta_low)
```



## SVM
 
```{r, echo=FALSE}
model_svm <- train(rating ~ .,
                  data = filtered_yelp_train,
                  method = "svmRadial",
                  trControl=ctrl,   # Radial kernel
                  tuneLength = 10)

predict_yelp_svm <- predict(model_svm, yelp_test_x)
postResample(predict_yelp_svm, yelp_test_y$rating)

# creating grid of data to plot results
grid <- filtered_yelp_test %>%
  gather_predictions(model_svm)

varImp(model_svm) # getting most important variables


# 5 features 
#censusIncomePerCapita
p6 <- ggplot(filtered_yelp_test, aes(as.factor(rating), censusIncomePerCapita)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p6

#censusGiniIndexOfInequality
p7 <- ggplot(filtered_yelp_test, aes(as.factor(rating), censusGiniIndexOfInequality)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p7

#reviewCount
p8 <- ggplot(filtered_yelp_test, aes(as.factor(rating), reviewCount)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p8

#censusMedianHHIncome
p9 <- ggplot(filtered_yelp_test, aes(as.factor(rating), censusMedianHHIncome)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red") + 
  scale_y_continuous(name="censusMedianHHIncome", labels = scales::comma)

p9

#price 
p10 <- ggplot(filtered_yelp_test, aes(as.factor(rating), price)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p10

```

## SPLINE
```{r, echo=FALSE}

# takes awhile to run...
model_spline <- train(rating ~ ., # outcome is "medv", predictors=all other columns
                  data = filtered_yelp_train,  # training data
                  trControl=ctrl, # evaluation method
                  method = "gamSpline", # model: generalized addive model using splines
                  tuneLength = 30) # number of parameters to try

# getting performance on test set (as root mean squared error (L2 norm), R^2, mean absolute error (L1 norm))
predict_yelp_spline <- predict(model_spline, yelp_test_x)
postResample(predict_yelp_spline, yelp_test_y$rating)

# creating grid of data to plot results
grid <- filtered_yelp_test %>%
  gather_predictions(model_spline)

varImp(model_spline) # getting most important variables

varImp(model_svm) # getting most important variables


# 5 features 
#censusIncomePerCapita
p11 <- ggplot(filtered_yelp_test, aes(as.factor(rating), censusIncomePerCapita)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p11

#censusGiniIndexOfInequality
p12 <- ggplot(filtered_yelp_test, aes(as.factor(rating), censusGiniIndexOfInequality)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p12

#reviewCount
p13 <- ggplot(filtered_yelp_test, aes(as.factor(rating), reviewCount)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p13

#censusMedianHHIncome
p14 <- ggplot(filtered_yelp_test, aes(as.factor(rating), censusMedianHHIncome)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red") + 
  scale_y_continuous(name="censusMedianHHIncome", labels = scales::comma)

p14

#price 
p15 <- ggplot(filtered_yelp_test, aes(as.factor(rating), price)) +
  geom_violin() +
  geom_boxplot(width=0.1) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="blue") +
  stat_summary(fun.y=median, geom="point", size=2, color="red")

p15
```

## Limitations (Our first attempt)
```{r, echo=FALSE}
model_spline <- train(rating ~ ., # outcome is "medv", predictors=all other columns
                  data = filtered_yelp_train,  # training data
                  trControl=ctrl, # evaluation method
                  method = "gamSpline", # model: generalized addive model using splines
                  tuneLength = 30) # number of parameters to try

# getting performance on test set (as root mean squared error (L2 norm), R^2, mean absolute error (L1 norm))
predict_yelp_spline <- predict(model_spline, yelp_test_x)
postResample(predict_yelp_spline, yelp_test_y$rating)

# creating grid of data to plot results
grid <- filtered_yelp_test %>%
  gather_predictions(model_spline)

varImp(model_spline) # getting most important variables

# only plotting prediction along most important variables
ggplot(filtered_yelp_test, aes(censusIncomePerCapita, rating, color=censusIncomePerCapita)) + 
  geom_point() + 
  geom_line(data = grid, aes(y = pred))

ggplot(filtered_yelp_test, aes(censusMedianHHIncome, rating, color=censusMedianHHIncome)) + 
  geom_point() + 
  geom_line(data = grid, aes(y = pred))
```


## Limitation part 2
```{r, echo=FALSE}
model_svm <- train(rating ~ .,
                  data = filtered_yelp_train,
                  method = "svmRadial",
                  trControl=ctrl,   # Radial kernel
                  tuneLength = 10)
model_svm
# getting performance on test set (as root mean squared error (L2 norm), R^2, mean absolute error (L1 norm))
predict_yelp_svm <- predict(model_svm, yelp_test_x)
postResample(predict_yelp_svm, yelp_test_y$rating)

# creating grid of data to plot results
grid <- filtered_yelp_test %>%
  gather_predictions(model_svm)

varImp(model_svm) # getting most important variables

filtered_yelp_test2 <- filtered_yelp_test %>% filter(rating == 3.5)

ggplot(filtered_yelp_test2, aes(censusIncomePerCapita, censusMedianHHIncome, color=as.factor(rating))) +
  geom_point() + 
  geom_line(data = grid, aes(y = pred))
```


```{r}
# finding number of ratings in each socioecnomic status
low.cutoff <- 62133
mid.cutoff <- 85696

num.ratings.low <- yelp.data %>% filter(censusMedianHHIncome < low.cutoff) %>% summarise(length(censusMedianHHIncome))
num.ratings.mid <- yelp.data %>% filter(censusMedianHHIncome > low.cutoff & censusMedianHHIncome < mid.cutoff) %>% summarise(length(censusMedianHHIncome))
num.ratings.high <- yelp.data %>% filter(censusMedianHHIncome > mid.cutoff) %>% summarise(length(censusMedianHHIncome))
```

```{r}
# finding number of ratings in each socioecnomic status
low.cutoff <- 39503
mid.cutoff <- 50908

num.income.low <- yelp.data %>% filter(censusIncomePerCapita < low.cutoff) %>% summarise(length(censusIncomePerCapita))
num.income.mid <- yelp.data %>% filter(censusIncomePerCapita > low.cutoff & censusIncomePerCapita < mid.cutoff) %>% summarise(length(censusIncomePerCapita))
num.income.high <- yelp.data %>% filter(censusIncomePerCapita > mid.cutoff) %>% summarise(length(censusIncomePerCapita))
```

```{r}
# finding number of ratings in each socioecnomic status
low.cutoff <- 0.41
mid.cutoff <- 0.50

num.gini.low <- yelp.data %>% filter(censusGiniIndexOfInequality < low.cutoff) %>% summarise(length(censusGiniIndexOfInequality))
num.gini.mid <- yelp.data %>% filter(censusGiniIndexOfInequality > low.cutoff & censusGiniIndexOfInequality < mid.cutoff) %>% summarise(length(censusGiniIndexOfInequality))
num.gini.high <- yelp.data %>% filter(censusGiniIndexOfInequality > mid.cutoff) %>% summarise(length(censusGiniIndexOfInequality))
```

```{r}
# counting the number of diff price within SES
num.price.low <- yelp.data %>% filter(censusMedianHHIncome < low.cutoff) %>% group_by(price) %>%
  summarise(total.count=n(), count=sum(is.na(price)))

num.price.mid <- yelp.data %>% filter(censusMedianHHIncome > low.cutoff & censusMedianHHIncome < mid.cutoff) %>% group_by(price) %>%
  summarise(total.count=n(), count=sum(is.na(price)))

num.price.high <- yelp.data %>% filter(censusMedianHHIncome > mid.cutoff) %>% group_by(price) %>%
  summarise(total.count=n(), count=sum(is.na(price)))


test.yelp.data <- yelp.data %>% mutate(SESMedianHH = ifelse(censusMedianHHIncome < 62133, 0, 
                                                    ifelse(censusMedianHHIncome > 85696, 2, 1)))

# ratingFreq <- table(test.yelp.data$rating, test.yelp.data$SESMedianHH)

ggplot(test.yelp.data, mapping = aes(x=rating, fill=as.factor(SESMedianHH))) + 
  geom_histogram(aes(y=..count../sum(..count..)))

```
