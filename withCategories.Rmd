---
title: "withCategories"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, include=FALSE}
if(!require(mlbench)){install.packages("mlbench"); require(mlbench)} # common datasets to use
if(!require(tidyverse)){install.packages("tidyverse"); library(tidyverse)} 
if(!require(modelr)){install.packages("modelr"); library(modelr)} 
# some dependencies for caret that aren't automatically installed
if(!require(ModelMetrics)){install.packages("ModelMetrics"); require(ModelMetrics)}
if(!require(recipes)){install.packages("recipes"); require(recipes)}
if(!require(DEoptimR)){install.packages("DEoptimR"); require(DEoptimR)}

if(!require(caret)){install.packages("caret"); require(caret)} # ML package WITHOUT its dependencies. Should not take as long
if(!require(dplyr)){install.packages("dplyr"); require(dplyr)}
if(!require(jsonlite)){install.packages("jsonlite"); require(jsonlite)}
set.seed(370)
```

## Reading and Organization Yelp Restaurants Dataset
```{r, echo=FALSE, include=FALSE}
# Getting data
json_file <- "SeattleYelpRestaurantsWithCategory.json"
yelp.data <- fromJSON(json_file) %>% filter(!is.na(price)) %>% filter(!is.na(reviewCount)) %>% filter(!is.na(censusMedianHHIncome)) %>% filter(!is.na(censusIncomePerCapita)) %>% filter(!is.na(censusGiniIndexOfInequality)) %>% filter(!is.na(rating)) %>% filter(!is.na(category)) 
low <- quantile(yelp.data$censusMedianHHIncome, 0.33) # cutoff number
high <- quantile(yelp.data$censusMedianHHIncome, 0.66) # cutoff number

below.avg <- yelp.data %>% filter(censusMedianHHIncome < low)
above.avg <- yelp.data %>% filter(censusMedianHHIncome > high)

below.avg.wo.census <- subset(below.avg, select=c("reviewCount", "price", "rating"))
above.avg.wo.census <- subset(above.avg, select=c("reviewCount", "price", "rating"))
#above.avg.wo.census$category <- as.factor(above.avg.wo.census$category)


filtered.yelp.w.census <- subset(yelp.data, select=c("reviewCount", "censusMedianHHIncome", "censusIncomePerCapita", "censusGiniIndexOfInequality", "category", "price"))


price.num <- c(nchar(yelp.data[,"price"]))
# price and rating for data w census
filtered.yelp.w.census$price = price.num
filtered.yelp.w.census$rating = yelp.data[,"rating"]

#price and rating for below averge filtered data
price.num.below <- c(nchar(below.avg.wo.census[,"price"]))
below.avg.wo.census$price = price.num.below

#price and rating for above average filtered data
price.num.above <- c(nchar(above.avg.wo.census[,"price"]))
above.avg.wo.census$price = price.num.above

```
## Correlation (need to confirm whether category should be a numeric value or factor)
```{r, echo=FALSE}
#filtered.yelp.w.census$category <- as.factor(filtered.yelp.w.census$category)
corr_matrix <- cor(filtered.yelp.w.census)# correlations between all predictor vars

cutoff <- 0.2 # should be higher in practice

highly_corr <- findCorrelation(corr_matrix, cutoff=cutoff)
print(colnames(filtered.yelp)[highly_corr]) # age is highly correalted with pregnant
```

## Ranked by Importance (need to confirm whether category should be a numeric value or factor)
```{r, echo=FALSE}
filtered.yelp.w.ratings <- filtered.yelp
no.na.rating <- yelp.data[,"rating"]
filtered.yelp.w.ratings$rating <- no.na.rating[!is.na(no.na.rating)]
control <- trainControl(method="repeatedcv", number = 10, repeats = 3)

model <- train(rating ~., data=filtered.yelp.w.ratings, method = "knn", preProcess = "scale", trControl = control)

importance <- varImp(model)

ggplot(importance)
```

## RFE (need to confirm whether category should be a numeric value or factor)
```{r, echo=FALSE}
control <- rfeControl(functions = rfFuncs, method="cv", number=10)
results <- rfe(filtered.yelp.w.ratings[,1:5], filtered.yelp.w.ratings[,6], sizes = c(1:5), rfeControl = control)

results
ggplot(results)
```

## Create proportion for high and low SES resturants
```{r, echo=FALSE, include=FALSE}
# splitting boston data into train+validate and test sets

split_proportion = 0.8

# select outcome variable for below avg HH income
below.avg.outcome <- below.avg.wo.census %>% dplyr::select(rating) # rating column only

# randomly select indices for train/validate set
below.avg.train_ind <- createDataPartition(below.avg.outcome$rating, p = split_proportion, list = FALSE)
below.avg.train <- below.avg.wo.census[below.avg.train_ind,] # get training below avg data
below.avg.test <- below.avg.wo.census[-below.avg.train_ind,] # get test below avg data

# select outcome variable for above avg HH income
above.avg.outcome <- above.avg.wo.census %>% dplyr::select(rating) # rating column only

# randomly select indices for train/validate set
above.avg.train_ind <- createDataPartition(above.avg.outcome$rating, p = split_proportion, list = FALSE)
above.avg.train <- above.avg.wo.census[above.avg.train_ind,] # get training above avg data
above.avg.test <- above.avg.wo.census[-above.avg.train_ind,] # get test above avg data

#yelp_test_x <- filtered.yelp %>% dplyr::select(-rating) # select predictor data for test set
#yelp_test_y <- filtered.yelp %>% dplyr::select(rating) # select outcome data for test set
```
## Creating training control
```{r, echo=FALSE, include=FALSE}
ctrl <- trainControl(method = "repeatedcv", number=10, repeats=3) # 10 fold cross-validation, repeated 3 times. better way to do it but takes longer.
```

## SVM Regression Model for High SES Restaurants
```{r}
# high SES SVM modeling
model_svm_high <- train(rating ~ .,
                  data = above.avg.train,
                  method = "svmRadial",
                  trControl=ctrl,   # Radial kernel
                  tuneLength = 10)

predict_yelp_svm_high <- predict(model_svm_high, below.avg.test)
#postResample(predict_yelp_svm_high, below.avg$rating)

#actual minus predicted
delta.high.SES <- below.avg.test$rating - predict_yelp_svm_high
count.high.SES.line <- length(which(delta.high.SES < 0)) / length(delta.high.SES)
count.high.SES.line
```


## SVM Regression Model for low SES Restaurants
```{r}
# low SES SVM modeling
model_svm_low <- train(rating ~ .,
                  data = below.avg.train,
                  method = "svmRadial",
                  trControl=ctrl,   # Radial kernel
                  tuneLength = 10)

predict_yelp_svm_low <- predict(model_svm_low, above.avg.test)
#postResample(predict_yelp_svm_low, below.avg$rating)

#actual minus predicted
delta.low.SES <- above.avg.test$rating - predict_yelp_svm_low
count.low.SES.line <- length(which(delta.low.SES < 0)) / length(delta.low.SES)
count.low.SES.line
```

## Organize Data for Subway

``` {r}
# filter only Subways for high and low SES
above.avg.subway <- filter(above.avg, name %in% "Subway")
below.avg.subway <- filter(below.avg, name %in% "Subway")

# filter out to only predictor variables
above.avg.subway.wo.census <- subset(above.avg.subway, select=c("reviewCount", "price", "rating"))
below.avg.subway.wo.census <- subset(below.avg.subway, select=c("reviewCount", "price", "rating"))

#turn price into numeric for above average subway filtered data
subway.price.num.above <- c(nchar(above.avg.subway.wo.census[,"price"]))
above.avg.subway.wo.census$price = subway.price.num.above

#turn price into numeric value for below averge subway filtered data
subway.price.num.below <- c(nchar(below.avg.subway.wo.census[,"price"]))
below.avg.subway.wo.census$price = subway.price.num.below

above.avg.subway.wo.census
below.avg.subway.wo.census
```

## Create proportion for high and low SES Subway
```{r, echo=FALSE, include=FALSE}
# splitting boston data into train+validate and test sets

split_proportion = 0.8

# select outcome variable for below avg HH income
below.avg.subway.outcome <- below.avg.subway.wo.census %>% dplyr::select(rating) # rating column only

# randomly select indices for train/validate set
below.avg.subway.train_ind <- createDataPartition(below.avg.subway.outcome$rating, p = split_proportion, list = FALSE)
below.avg.subway.train <- below.avg.subway.wo.census[below.avg.subway.train_ind,] # get training below avg data
below.avg.subway.test <- below.avg.subway.wo.census[-below.avg.subway.train_ind,] # get test below avg data

# select outcome variable for above avg HH income
above.avg.subway.outcome <- above.avg.subway.wo.census %>% dplyr::select(rating) # rating column only

# randomly select indices for train/validate set
above.avg.subway.train_ind <- createDataPartition(above.avg.subway.outcome$rating, p = split_proportion, list = FALSE)
above.avg.subway.train <- above.avg.subway.wo.census[above.avg.subway.train_ind,] # get training above avg data
above.avg.subway.test <- above.avg.subway.wo.census[-above.avg.subway.train_ind,] # get test above avg data
```

## Creating training control for subway
```{r, echo=FALSE, include=FALSE}
ctrl <- trainControl(method = "repeatedcv", number=10, repeats=3) # 10 fold cross-validation, repeated 3 times. better way to do it but takes longer.
```


## SVM Regression Model for High SES Subway
```{r}
# high SES SVM modeling
subway_lm_high <- train(rating ~ reviewCount,
                  data = above.avg.subway.train,
                  method = "lm")

subway_lm_high_2 <- lm(formula = rating ~ reviewCount * price, data = above.avg.subway.train)
summary(subway_lm_high_2)

predict_subway_svm_high <- predict(subway.model_svm_high, below.avg.subway.test)
#postResample(predict_yelp_svm_high, below.avg$rating)

#actual minus predicted
delta.subway.high.SES <- below.avg.subway.test$rating - predict_subway_svm_high
count.subway.high.SES.line <- length(which(delta.subway.high.SES < 0)) / length(delta.subway.high.SES)
count.high.SES.line
```
## Plotting all Yelp Restaurants in Maps

``` {r}
install.packages("ggmap")
library(ggmap)

mapgilbert <- get_map(location = c(lon = mean(yelp.data$longitude), lat = mean(yelp.data$latitude)), zoom = 11, maptype = "roadmap", scale = "auto")

# plotting the map with some points on it
ggmap(mapgilbert) +
  geom_point(data = yelp.data, aes(x = yelp.data$longitude, y = yelp.data$latitude, fill = "red", alpha = 0.8), size = 2, shape = 21) +
  guides(fill=FALSE, alpha=FALSE, size=FALSE)

```
